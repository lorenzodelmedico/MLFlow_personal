{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Tracking and Model Management with MLFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to use the MLFlow Tracking API. For simple local uses, the best is to leave the data management to MLFlow and let it store runs, metrics, models and artifacts locally. For more advanced usage, all of this information can be stored in databases. You can find the detailed on MLFlow's documentation [here](https://mlflow.org/docs/latest/tracking.html#scenario-1-mlflow-on-localhost)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring MLFlow\n",
    "\n",
    "MLflow setup:\n",
    "* Tracking server: no\n",
    "* Backend store: local filesystem\n",
    "* Artifacts store: local filesystem\n",
    "\n",
    "The experiments can be explored locally by launching the MLflow UI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the tracking server URI, where the experiments and runs are going to be logged. We observe it refers to a local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://localhost:5002'\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5002\")\n",
    "\n",
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this initialization, we can connect create a client to connect to the API and see what experiments are present."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By refering to mlflow's [documentation](https://mlflow.org/docs/latest/python_api/mlflow.client.html), create a client and display a list of the available experiments using the search_experiments function. This function could prove useful later to programatically explore experiments (rather than in the UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment ID: 588343512068939149, Name: taxi-trip-duration\n",
      "Experiment ID: 605513876365684597, Name: iris-experiment-1\n",
      "Experiment ID: 0, Name: Default\n"
     ]
    }
   ],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "experiments = client.search_experiments()\n",
    "for experiment in experiments:\n",
    "    print(f\"Experiment ID: {experiment.experiment_id}, Name: {experiment.name}\")\n",
    "### STRIP_START ###\n",
    "### STRIP_END ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is a default experiment for which the runs are stored locally in the mlruns folder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an experiment and logging a new run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An experiment is a logical entity regrouping the logs of multiple attempts at solving a same problem, called runs. \\\n",
    "We will now work with the classic sklearn dataset iris. Our goal here is to manage to classify the different iris species. To track our models performance, we will log every attempt as a \"run\" and create a new experiment \"iris-experiment-1\" to regroup them."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lookup the mlflow.run and mlflow.start_run functions [here](https://mlflow.org/docs/latest/python_api/mlflow.html?highlight=start_run#mlflow.start_run) to find out how to manage runs.\n",
    "Explore [this part](https://mlflow.org/docs/latest/python_api/mlflow.html) to learn more about the log_params, log_metrics and log_artifact functions. Find out how to log sklearn models [here](https://mlflow.org/docs/latest/python_api/mlflow.sklearn.html])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following in order to log the parameters, interesting metrics and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/05 16:54:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'iris_lr_model' already exists. Creating a new version of this model...\n",
      "2025/02/05 16:54:39 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: iris_lr_model, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default artifacts URI: 'mlflow-artifacts:/605513876365684597/991ff26161f9418587c9d05088e59dba/artifacts'\n",
      "üèÉ View run bouncy-wolf-956 at: http://localhost:5002/#/experiments/605513876365684597/runs/991ff26161f9418587c9d05088e59dba\n",
      "üß™ View experiment at: http://localhost:5002/#/experiments/605513876365684597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'iris_lr_model'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "mlflow.set_experiment(\"iris-experiment-1\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "    \n",
    "    # Set tags for the run\n",
    "    mlflow.set_tag(\"model\", \"Logistic Regression\")\n",
    "    mlflow.set_tag(\"dataset\", \"Iris\")\n",
    "    \n",
    "    X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    params = {\"C\": 0.1, \"random_state\": 42}\n",
    "    model = LogisticRegression(**params).fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    ### STRIP_START ###\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(model, \"model\") \n",
    "    ### STRIP_END ###   \n",
    "    \n",
    "    # Register your model in mlflow model registry\n",
    "    result = mlflow.register_model(f\"runs:/{run_id}/model\", \"iris_lr_model\")\n",
    "\n",
    "    print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try running the training script with various parameters to have runs to compare.\n",
    "You can now explore your run(s) using the ui: \\\n",
    "(Paste \"mlflow ui --host 0.0.0.0 --port 5002\" in your terminal, or run the cell below)\n",
    "\n",
    "**N.B.** Make sure you are in the lecture folder and not the repo root!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-05 16:54:41 +0100] [23225] [INFO] Starting gunicorn 23.0.0\n",
      "[2025-02-05 16:54:41 +0100] [23225] [INFO] Listening at: http://0.0.0.0:5004 (23225)\n",
      "[2025-02-05 16:54:41 +0100] [23225] [INFO] Using worker: sync\n",
      "[2025-02-05 16:54:41 +0100] [23226] [INFO] Booting worker with pid: 23226\n",
      "[2025-02-05 16:54:41 +0100] [23227] [INFO] Booting worker with pid: 23227\n",
      "[2025-02-05 16:54:41 +0100] [23228] [INFO] Booting worker with pid: 23228\n",
      "[2025-02-05 16:54:41 +0100] [23229] [INFO] Booting worker with pid: 23229\n",
      "[2025-02-05 16:55:30 +0100] [23225] [CRITICAL] WORKER TIMEOUT (pid:23228)\n",
      "[2025-02-05 16:55:30 +0100] [23228] [ERROR] Error handling request (no URI read)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/workers/sync.py\", line 133, in handle\n",
      "    req = next(parser)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/parser.py\", line 41, in __next__\n",
      "    self.mesg = self.mesg_class(self.cfg, self.unreader, self.source_addr, self.req_count)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 259, in __init__\n",
      "    super().__init__(cfg, unreader, peer_addr)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 60, in __init__\n",
      "    unused = self.parse(self.unreader)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 271, in parse\n",
      "    self.get_data(unreader, buf, stop=True)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 262, in get_data\n",
      "    data = unreader.read()\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/unreader.py\", line 36, in read\n",
      "    d = self.chunk()\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/unreader.py\", line 63, in chunk\n",
      "    return self.sock.recv(self.mxchunk)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 204, in handle_abort\n",
      "    sys.exit(1)\n",
      "SystemExit: 1\n",
      "[2025-02-05 16:55:30 +0100] [23228] [INFO] Worker exiting (pid: 23228)\n",
      "[2025-02-05 16:55:30 +0100] [23396] [INFO] Booting worker with pid: 23396\n",
      "^C\n",
      "[2025-02-05 16:56:12 +0100] [23225] [INFO] Handling signal: int\n",
      "[2025-02-05 16:56:12 +0100] [23226] [INFO] Worker exiting (pid: 23226)\n",
      "[2025-02-05 16:56:12 +0100] [23229] [INFO] Worker exiting (pid: 23229)\n",
      "[2025-02-05 16:56:12 +0100] [23396] [INFO] Worker exiting (pid: 23396)\n",
      "[2025-02-05 16:56:12 +0100] [23227] [ERROR] Error handling request (no URI read)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/workers/sync.py\", line 133, in handle\n",
      "    req = next(parser)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/parser.py\", line 41, in __next__\n",
      "    self.mesg = self.mesg_class(self.cfg, self.unreader, self.source_addr, self.req_count)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 259, in __init__\n",
      "    super().__init__(cfg, unreader, peer_addr)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 60, in __init__\n",
      "    unused = self.parse(self.unreader)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 271, in parse\n",
      "    self.get_data(unreader, buf, stop=True)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/message.py\", line 262, in get_data\n",
      "    data = unreader.read()\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/unreader.py\", line 36, in read\n",
      "    d = self.chunk()\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/http/unreader.py\", line 63, in chunk\n",
      "    return self.sock.recv(self.mxchunk)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 198, in handle_quit\n",
      "    time.sleep(0.1)\n",
      "  File \"/home/lordbenzo/.pyenv/versions/3.10.12/envs/Artefact/lib/python3.10/site-packages/gunicorn/workers/base.py\", line 199, in handle_quit\n",
      "    sys.exit(0)\n",
      "SystemExit: 0\n",
      "[2025-02-05 16:56:12 +0100] [23227] [INFO] Worker exiting (pid: 23227)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui --host 0.0.0.0 --port 5004"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will have to kill the cell to continue experimenting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the model registry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are satisfied with the last run's model, you can transform the logged model into a registered model. It will be logged in the Model Registry, which makes it easier to use in production and manage versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'iris_lr_model' already exists. Creating a new version of this model...\n",
      "2025/02/05 16:56:16 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: iris_lr_model, version 4\n",
      "Created version '4' of model 'iris_lr_model'.\n"
     ]
    }
   ],
   "source": [
    "# We already have our run id from above. Let's use it to register the model\n",
    "\n",
    "result = mlflow.register_model(f\"runs:/{run_id}/models\", \"iris_lr_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will get back to our taxi rides use case: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from typing import List\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown --quiet\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "DATA_FOLDER = \"../../data\"\n",
    "train_path = f\"{DATA_FOLDER}/yellow_tripdata_2021-01.parquet\"\n",
    "test_path = f\"{DATA_FOLDER}/yellow_tripdata_2021-02.parquet\"\n",
    "predict_path = f\"{DATA_FOLDER}/yellow_tripdata_2021-03.parquet\"\n",
    "\n",
    "\n",
    "if not os.path.exists(DATA_FOLDER):\n",
    "    os.makedirs(DATA_FOLDER)\n",
    "    print(f\"New directory {DATA_FOLDER} created!\")\n",
    "\n",
    "    gdown.download(\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\",\n",
    "        train_path,\n",
    "        quiet=False,\n",
    "    )\n",
    "    gdown.download(\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet\",\n",
    "        test_path,\n",
    "        quiet=False,\n",
    "    )\n",
    "    gdown.download(\n",
    "        \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-03.parquet\",\n",
    "        predict_path,\n",
    "        quiet=False,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:30:10</td>\n",
       "      <td>2021-01-01 00:36:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:51:20</td>\n",
       "      <td>2021-01-01 00:52:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238</td>\n",
       "      <td>151</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:43:30</td>\n",
       "      <td>2021-01-01 01:11:06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>51.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01 00:15:48</td>\n",
       "      <td>2021-01-01 00:31:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>36.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:31:49</td>\n",
       "      <td>2021-01-01 00:48:21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.36</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2021-01-01 00:30:10   2021-01-01 00:36:12              1.0   \n",
       "1         1  2021-01-01 00:51:20   2021-01-01 00:52:19              1.0   \n",
       "2         1  2021-01-01 00:43:30   2021-01-01 01:11:06              1.0   \n",
       "3         1  2021-01-01 00:15:48   2021-01-01 00:31:01              0.0   \n",
       "4         2  2021-01-01 00:31:49   2021-01-01 00:48:21              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           2.10         1.0                  N           142            43   \n",
       "1           0.20         1.0                  N           238           151   \n",
       "2          14.70         1.0                  N           132           165   \n",
       "3          10.60         1.0                  N           138           132   \n",
       "4           4.94         1.0                  N            68            33   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          8.0    3.0      0.5        0.00           0.0   \n",
       "1             2          3.0    0.5      0.5        0.00           0.0   \n",
       "2             1         42.0    0.5      0.5        8.65           0.0   \n",
       "3             1         29.0    0.5      0.5        6.05           0.0   \n",
       "4             1         16.5    0.5      0.5        4.06           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         11.80                   2.5          NaN  \n",
       "1                    0.3          4.30                   0.0          NaN  \n",
       "2                    0.3         51.95                   0.0          NaN  \n",
       "3                    0.3         36.35                   0.0          NaN  \n",
       "4                    0.3         24.36                   2.5          NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(path: str):\n",
    "    return pd.read_parquet(path)\n",
    "\n",
    "\n",
    "train_df = load_data(train_path)\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Prepare the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the data to make it Machine Learning ready. \\\n",
    "For this, we need to clean it, compute the target (what we want to predict), and compute some features to help the model understand the data better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1 Compute the target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict a taxi trip duration in minutes. Let's compute it as a difference between the drop-off time and the pick-up time for each trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_target(\n",
    "    df: pd.DataFrame,\n",
    "    pickup_column: str = \"tpep_pickup_datetime\",\n",
    "    dropoff_column: str = \"tpep_dropoff_datetime\",\n",
    ") -> pd.DataFrame:\n",
    "    df[\"duration\"] = df[dropoff_column] - df[pickup_column]\n",
    "    df[\"duration\"] = df[\"duration\"].dt.total_seconds() / 60\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = compute_target(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.343254e+06\n",
       "mean     1.164406e+01\n",
       "std      8.865269e+00\n",
       "min      1.000000e+00\n",
       "25%      5.700000e+00\n",
       "50%      9.150000e+00\n",
       "75%      1.463333e+01\n",
       "max      6.000000e+01\n",
       "Name: duration, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"duration\"].describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove outliers and reduce the scope to trips between 1 minute and 1 hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_DURATION = 1\n",
    "MAX_DURATION = 60\n",
    "\n",
    "\n",
    "def filter_outliers(df: pd.DataFrame, min_duration: int = 1, max_duration: int = 60) -> pd.DataFrame:\n",
    "    return df[df[\"duration\"].between(min_duration, max_duration)]\n",
    "\n",
    "\n",
    "train_df = filter_outliers(train_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2 Prepare features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2-1 Categorical features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most machine learning models don't work with categorical features. Because of this, they must be transformed so that the ML model can consume them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLS = [\"PULocationID\", \"DOLocationID\"]\n",
    "\n",
    "\n",
    "def encode_categorical_cols(df: pd.DataFrame, categorical_cols: List[str] = None) -> pd.DataFrame:\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = [\"PULocationID\", \"DOLocationID\", \"passenger_count\"]\n",
    "    df[categorical_cols] = df[categorical_cols].fillna(-1).astype(\"int\")\n",
    "    df[categorical_cols] = df[categorical_cols].astype(\"str\")\n",
    "    return df\n",
    "\n",
    "\n",
    "train_df = encode_categorical_cols(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_x_y(\n",
    "    df: pd.DataFrame,\n",
    "    categorical_cols: List[str] = None,\n",
    "    dv: DictVectorizer = None,\n",
    "    with_target: bool = True,\n",
    ") -> dict:\n",
    "\n",
    "    if categorical_cols is None:\n",
    "        categorical_cols = [\"PULocationID\", \"DOLocationID\", \"passenger_count\"]\n",
    "    dicts = df[categorical_cols].to_dict(orient=\"records\")\n",
    "\n",
    "    y = None\n",
    "    if with_target:\n",
    "        if dv is None:\n",
    "            dv = DictVectorizer()\n",
    "            dv.fit(dicts)\n",
    "        y = df[\"duration\"].values\n",
    "\n",
    "    x = dv.transform(dicts)\n",
    "    return x, y, dv\n",
    "\n",
    "\n",
    "X_train, y_train, dv = extract_x_y(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343254, 528)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343254,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a basic linear regression model to have a baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train: csr_matrix, y_train: np.ndarray):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(x_train, y_train)\n",
    "    return lr\n",
    "\n",
    "\n",
    "model = train_model(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Evaluate model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate the model on train and test data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1 On train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.782411841111456"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_duration(input_data: csr_matrix, model: LinearRegression):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\n",
    "def evaluate_model(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    return root_mean_squared_error(y_true, y_pred)\n",
    "\n",
    "\n",
    "prediction = predict_duration(X_train, model)\n",
    "train_me = evaluate_model(y_train, prediction)\n",
    "train_me"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 On test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = load_data(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = compute_target(test_df)\n",
    "test_df = encode_categorical_cols(test_df)\n",
    "X_test, y_test, _ = extract_x_y(test_df, dv=dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.375056461631154"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = predict_duration(X_test, model)\n",
    "test_me = evaluate_model(y_test, y_pred_test)\n",
    "test_me"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Log Model Parameters to MlFlow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all our development functions are built and tested, let's create a training pipeline and log the training parameters, logs and model to MlFlow."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a training flow, log all the important parameters, metrics and model. Try to find what could be important and needs to be logged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame columns: Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee', 'duration'],\n",
      "      dtype='object')\n",
      "Test DataFrame columns: Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
      "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
      "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
      "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
      "       'total_amount', 'congestion_surcharge', 'airport_fee', 'duration'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/02/05 18:14:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n",
      "Registered model 'taxi_trip_lr_model' already exists. Creating a new version of this model...\n",
      "2025/02/05 18:14:23 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: taxi_trip_lr_model, version 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run polite-skink-767 at: http://localhost:5002/#/experiments/588343512068939149/runs/02552bb469f942a58470ecb3f307303e\n",
      "üß™ View experiment at: http://localhost:5002/#/experiments/588343512068939149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '3' of model 'taxi_trip_lr_model'.\n"
     ]
    }
   ],
   "source": [
    "# Set the experiment name\n",
    "mlflow.set_experiment(\"taxi-trip-duration\")\n",
    "\n",
    "# Start a run\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "\n",
    "    # Set tags for the run\n",
    "    mlflow.set_tag(\"model\", \"Linear Regression\")\n",
    "    mlflow.set_tag(\"dataset\", \"Taxi Trip Data\")\n",
    "\n",
    "    # Load data\n",
    "    train_df = load_data(train_path)\n",
    "    test_df = load_data(test_path)\n",
    "\n",
    "    # Compute target\n",
    "    train_df = compute_target(train_df)\n",
    "    test_df = compute_target(test_df)\n",
    "\n",
    "    # Filter outliers\n",
    "    train_df = filter_outliers(train_df)\n",
    "    test_df = filter_outliers(test_df)\n",
    "    \n",
    "    # Print columns to debug\n",
    "    print(\"Train DataFrame columns:\", train_df.columns)\n",
    "    print(\"Test DataFrame columns:\", test_df.columns)\n",
    "    \n",
    "    # Encode categorical columns\n",
    "    train_df = encode_categorical_cols(train_df, CATEGORICAL_COLS)\n",
    "    test_df = encode_categorical_cols(test_df, CATEGORICAL_COLS)\n",
    "\n",
    "    # Extract X and y\n",
    "    X_train, y_train, dv = extract_x_y(train_df, categorical_cols=CATEGORICAL_COLS)\n",
    "    X_test, y_test, _ = extract_x_y(test_df, categorical_cols=CATEGORICAL_COLS, dv=dv)\n",
    "\n",
    "    # Train model\n",
    "    model = train_model(X_train, y_train)\n",
    "\n",
    "    # Evaluate model\n",
    "    train_pred = predict_duration(X_train, model)\n",
    "    train_rmse = evaluate_model(y_train, train_pred)\n",
    "    mlflow.log_metric(\"train_rmse\", train_rmse)\n",
    "\n",
    "    # Evaluate model on test set\n",
    "    test_pred = predict_duration(X_test, model)\n",
    "    test_rmse = evaluate_model(y_test, test_pred)\n",
    "    mlflow.log_metric(\"test_rmse\", test_rmse)\n",
    "\n",
    "    # Log your model\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Register your model in mlflow model registry\n",
    "    result = mlflow.register_model(f\"runs:/{run_id}/model\", \"taxi_trip_lr_model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model is satisfactory, we stage it as production using the appropriate version. This will help us retreiving it for predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a mlflow client and use the [mlflow documentation](https://mlflow.org/docs/latest/python_api/mlflow.client.html?highlight=transition_model_version_stage#mlflow.client.MlflowClient.transition_model_version_stage) to stage the appropriate model as being in \"production\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23100/1350356063.py:4: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/latest/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1738775663673, current_stage='Production', description='', last_updated_timestamp=1738775663713, name='taxi_trip_lr_model', run_id='02552bb469f942a58470ecb3f307303e', run_link='', source='mlflow-artifacts:/588343512068939149/02552bb469f942a58470ecb3f307303e/artifacts/model', status='READY', status_message=None, tags={}, user_id='', version='3'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "### STRIP_START ###\n",
    "#TODO:\n",
    "client.transition_model_version_stage(\n",
    "    name=\"taxi_trip_lr_model\",\n",
    "    version=result.version,\n",
    "    stage=\"Production\"\n",
    ")\n",
    "### STRIP_END ###"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our model to predict on fresh unseen data and forecast what is going to be the duration of a tawi trip depending on trip characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: iris_lr_model\n",
      "  Version: 4\n",
      "  Stage: None\n",
      "  URI: mlflow-artifacts:/605513876365684597/991ff26161f9418587c9d05088e59dba/artifacts/models\n",
      "Name: taxi_trip_lr_model\n",
      "  Version: 3\n",
      "  Stage: Production\n",
      "  URI: mlflow-artifacts:/588343512068939149/02552bb469f942a58470ecb3f307303e/artifacts/model\n"
     ]
    }
   ],
   "source": [
    "# List all registered models\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "for rm in client.search_registered_models():\n",
    "    print(f\"Name: {rm.name}\")\n",
    "    for version in rm.latest_versions:\n",
    "        print(f\"  Version: {version.version}\")\n",
    "        print(f\"  Stage: {version.current_stage}\")\n",
    "        print(f\"  URI: {version.source}\")\n",
    "\n",
    "# Set the mlflow_experiment_path to the name of the registered model\n",
    "mlflow_experiment_path = \"taxi_trip_lr_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343254,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343254, 518)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load prediction data\n",
    "predict_df = load_data(predict_path)\n",
    "\n",
    "predict_df = compute_target(predict_df)\n",
    "predict_df = filter_outliers(predict_df)\n",
    "predict_df = encode_categorical_cols(predict_df, CATEGORICAL_COLS)  \n",
    "X_pred, y, dv = extract_x_y(predict_df, categorical_cols=CATEGORICAL_COLS, dv=dv, with_target=True)\n",
    "\n",
    "# Load production model in mlflow in a variable `model`\n",
    "model = None\n",
    "### STRIP_START ###\n",
    "model_uri = f\"models:/{mlflow_experiment_path}/production\"\n",
    "model = mlflow.sklearn.load_model(model_uri) \n",
    "### STRIP_END ###\n",
    "\n",
    "# Make predictions\n",
    "y_pred = predict_duration(X_pred, model)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-01 00:22:02</td>\n",
       "      <td>2021-03-01 00:23:22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>264</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-01 00:25:17</td>\n",
       "      <td>2021-03-01 00:31:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>152</td>\n",
       "      <td>152</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-01 00:07:40</td>\n",
       "      <td>2021-03-01 00:31:23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.65</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.3</td>\n",
       "      <td>70.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-01 00:02:13</td>\n",
       "      <td>2021-03-01 00:06:01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>68</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>2021-03-01 00:40:16</td>\n",
       "      <td>2021-03-01 00:50:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>262</td>\n",
       "      <td>1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>18.59</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.116667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         2  2021-03-01 00:22:02   2021-03-01 00:23:22              1.0   \n",
       "2         2  2021-03-01 00:25:17   2021-03-01 00:31:01              1.0   \n",
       "3         1  2021-03-01 00:07:40   2021-03-01 00:31:23              0.0   \n",
       "4         2  2021-03-01 00:02:13   2021-03-01 00:06:01              1.0   \n",
       "5         2  2021-03-01 00:40:16   2021-03-01 00:50:23              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag PULocationID DOLocationID  \\\n",
       "0           0.00         1.0                  N          264          264   \n",
       "2           0.00         1.0                  N          152          152   \n",
       "3          16.50         4.0                  N          138          265   \n",
       "4           1.13         1.0                  N           68          264   \n",
       "5           2.68         1.0                  N          239          262   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             2          3.0    0.5      0.5        0.00          0.00   \n",
       "2             2          3.5    0.5      0.5        0.00          0.00   \n",
       "3             1         51.0    0.5      0.5       11.65          6.12   \n",
       "4             1          5.5    0.5      0.5        1.86          0.00   \n",
       "5             1         10.5    0.5      0.5        4.29          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \\\n",
       "0                    0.3          4.30                   0.0          NaN   \n",
       "2                    0.3          4.80                   0.0          NaN   \n",
       "3                    0.3         70.07                   0.0          NaN   \n",
       "4                    0.3         11.16                   2.5          NaN   \n",
       "5                    0.3         18.59                   2.5          NaN   \n",
       "\n",
       "    duration  \n",
       "0   1.333333  \n",
       "2   5.733333  \n",
       "3  23.716667  \n",
       "4   3.800000  \n",
       "5  10.116667  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'y_true' parameter of root_mean_squared_error must be an array-like. Got None instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_final \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train_final\n",
      "Cell \u001b[0;32mIn[48], line 6\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_model\u001b[39m(y_true: np\u001b[38;5;241m.\u001b[39mndarray, y_pred: np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mroot_mean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/Artefact/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:206\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    204\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 206\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n",
      "File \u001b[0;32m~/.pyenv/versions/Artefact/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'y_true' parameter of root_mean_squared_error must be an array-like. Got None instead."
     ]
    }
   ],
   "source": [
    "train_final = evaluate_model(y, y_pred)\n",
    "train_final"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - To go further"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you managed to go this far, you can try solving the use case using an other regression model like [XGBoost](https://xgboost.readthedocs.io/en/stable/) for instance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Artefact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
